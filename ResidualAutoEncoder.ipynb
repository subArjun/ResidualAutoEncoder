{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from ResidualAutoEncoder import ResidualAutoencoder\n",
    "from ResidualAutoEncoder import Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arjun\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Arjun\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Arjun\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "c:\\Users\\Arjun\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: nan, recon_loss: 0.0001 learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Hyperparameters\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    epochs = 5\n",
    "    \n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Data transformation and loading\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), ( 0.5)),\n",
    "        transforms.Resize((128, 128))\n",
    "    ])\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Model, loss function, and optimizer\n",
    "    model = ResidualAutoencoder(num_blocks=3, block_depth=2, bottleneck_dim=128, channels=3, device=device)\n",
    "    criterion = Criterion(model=model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Train the model\n",
    "    model.train_harness(model, train_loader, criterion, optimizer, epochs)\n",
    "    \n",
    "    torch.save(model.state_dict(), 'models/residual_autoencoder.pth')\n",
    "    # Evaluate the model\n",
    "    inputs, outputs = model.evaluate_harness(model, test_loader, device)\n",
    "    outputs = unnormalize(outputs)\n",
    "    # Visualize the results\n",
    "    num_images = 10\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(15, 4))\n",
    "    for i in range(num_images):\n",
    "        axes[0, i].imshow(inputs[i].permute(1, 2, 0))\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(outputs[i].permute(1, 2, 0))\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def unnormalize(tensor):\n",
    "    return tensor * 0.5 + 0.5\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 64 2 3 2\n",
      "64 128 2 3 2\n"
     ]
    }
   ],
   "source": [
    "model = ResidualAutoencoder(num_blocks=2, block_depth=2, bottleneck_dim=128, channels=3, asym_block=2, asym_depth=2)\n",
    "torch.save(model.state_dict(), 'models/residual_autoencorder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
